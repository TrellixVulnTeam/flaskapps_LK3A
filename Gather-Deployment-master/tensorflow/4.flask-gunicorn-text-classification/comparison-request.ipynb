{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/husein/space/text-dataset/sentiment/model-rnn-vector-huber.ckpt\n",
      "CPU times: user 816 ms, sys: 40 ms, total: 856 ms\n",
      "Wall time: 811 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model.Model(3, 256, 64, 2, 0.0001)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(sess, os.getcwd() + \"/model-rnn-vector-huber.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 ms, sys: 8 ms, total: 80 ms\n",
      "Wall time: 75.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "g=load_graph('frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "y = g.get_tensor_by_name('import/logits:0')\n",
    "sess = tf.InteractiveSession(graph=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze model loaded more faster than dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "import threading\n",
    "import requests\n",
    "\n",
    "def run_parallel_in_threads(target, args_list):\n",
    "    globalparas = []\n",
    "    result = Queue()\n",
    "    def task_wrapper(*args):\n",
    "        result.put(target(*args))\n",
    "    threads = [threading.Thread(target = task_wrapper, args = args) for args in args_list]\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    while not result.empty():\n",
    "        globalparas.append(result.get())\n",
    "    globalparas = list(filter(None, globalparas))\n",
    "    return globalparas\n",
    "\n",
    "def get_time(text, type_api, i):\n",
    "    response = str(requests.get(\"http://192.168.0.102:8033/%s?text=%s\"%(type_api, text)).content)\n",
    "    return [response, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress test 20 requests concurrently on dynamic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0, time taken 0.040708 s\n",
      "thread 2, time taken 0.072802 s\n",
      "thread 1, time taken 0.092469 s\n",
      "thread 4, time taken 0.108417 s\n",
      "thread 7, time taken 0.125185 s\n",
      "thread 9, time taken 0.146564 s\n",
      "thread 17, time taken 0.160176 s\n",
      "thread 3, time taken 0.196733 s\n",
      "thread 6, time taken 0.212126 s\n",
      "thread 10, time taken 0.230030 s\n",
      "thread 11, time taken 0.250885 s\n",
      "thread 15, time taken 0.269423 s\n",
      "thread 13, time taken 0.290279 s\n",
      "thread 18, time taken 0.308505 s\n",
      "thread 19, time taken 0.327376 s\n",
      "thread 5, time taken 0.364115 s\n",
      "thread 8, time taken 0.380689 s\n",
      "thread 14, time taken 0.395581 s\n",
      "thread 12, time taken 0.417496 s\n",
      "thread 16, time taken 0.430993 s\n",
      "total time taken 4.820551 s, average time taken 0.241028 s\n"
     ]
    }
   ],
   "source": [
    "CONCURRENT = 20\n",
    "threads = []\n",
    "for i in range(CONCURRENT):\n",
    "    threads.append(('Freeze model loaded more faster than dynamic model', 'dynamic', i,))\n",
    "outputs = run_parallel_in_threads(get_time, threads)\n",
    "total = 0\n",
    "for i in outputs:\n",
    "    total += float(i[0][2:-1])\n",
    "    print('thread %d, time taken %f s'%(i[1], float(i[0][2:-1])))\n",
    "    \n",
    "print('total time taken %f s, average time taken %f s'%(total, total / CONCURRENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress test 20 requests concurrently on static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0, time taken 0.052546 s\n",
      "thread 1, time taken 0.087430 s\n",
      "thread 2, time taken 0.111106 s\n",
      "thread 4, time taken 0.129980 s\n",
      "thread 5, time taken 0.139806 s\n",
      "thread 8, time taken 0.164908 s\n",
      "thread 10, time taken 0.169885 s\n",
      "thread 13, time taken 0.209557 s\n",
      "thread 16, time taken 0.213291 s\n",
      "thread 18, time taken 0.236292 s\n",
      "thread 6, time taken 0.267163 s\n",
      "thread 9, time taken 0.311357 s\n",
      "thread 14, time taken 0.314128 s\n",
      "thread 11, time taken 0.327267 s\n",
      "thread 19, time taken 0.364782 s\n",
      "thread 7, time taken 0.382049 s\n",
      "thread 12, time taken 0.384515 s\n",
      "thread 15, time taken 0.427014 s\n",
      "thread 17, time taken 0.428580 s\n",
      "thread 3, time taken 0.461565 s\n",
      "total time taken 5.183223 s, average time taken 0.259161 s\n"
     ]
    }
   ],
   "source": [
    "CONCURRENT = 20\n",
    "threads = []\n",
    "for i in range(CONCURRENT):\n",
    "    threads.append(('Freeze model loaded more faster than dynamic model', 'static', i,))\n",
    "outputs = run_parallel_in_threads(get_time, threads)\n",
    "total = 0\n",
    "for i in outputs:\n",
    "    total += float(i[0][2:-1])\n",
    "    print('thread %d, time taken %f s'%(i[1], float(i[0][2:-1])))\n",
    "    \n",
    "print('total time taken %f s, average time taken %f s'%(total, total / CONCURRENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 5 experiments on stress test 20 requests concurrently on dynamic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to run experiments 27.863281 s, average 5.572656 s\n"
     ]
    }
   ],
   "source": [
    "total_experiments = 0\n",
    "for _ in range(5):\n",
    "    CONCURRENT = 20\n",
    "    threads = []\n",
    "    for i in range(CONCURRENT):\n",
    "        threads.append(('Freeze model loaded more faster than dynamic model', 'dynamic', i,))\n",
    "    outputs = run_parallel_in_threads(get_time, threads)\n",
    "    total = 0\n",
    "    for i in outputs:\n",
    "        total += float(i[0][2:-1])\n",
    "    total_experiments += total\n",
    "    \n",
    "print('time taken to run experiments %f s, average %f s'%(total_experiments, total_experiments / 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 5 experiments on stress test 20 requests concurrently on static graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to run experiments 26.089081 s, average 5.217816 s\n"
     ]
    }
   ],
   "source": [
    "total_experiments = 0\n",
    "for _ in range(5):\n",
    "    CONCURRENT = 20\n",
    "    threads = []\n",
    "    for i in range(CONCURRENT):\n",
    "        threads.append(('Freeze model loaded more faster than dynamic model', 'static', i,))\n",
    "    outputs = run_parallel_in_threads(get_time, threads)\n",
    "    total = 0\n",
    "    for i in outputs:\n",
    "        total += float(i[0][2:-1])\n",
    "    total_experiments += total\n",
    "    \n",
    "print('time taken to run experiments %f s, average %f s'%(total_experiments, total_experiments / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
